\section{The Retrieval Architecture}
When humans think, there are at least two core processes involved. The first is the retrieval of information in memory, whether it be memories of events, concepts, or facts. What is retrieved must then be coordinated with the current context and objectives within that context, to produce thought as typically represented both internally (and often externally) in the form of language. This section outlines an expanded principle of retrieval in which features of identity or long-term states are retrieved and continuously incorporated into language generation. Current retrieval mechanisms such as RAG are useful for citing or justifying responses and mitigating hallucinations. However, databases can be used to do more than retrieve information, they can also be used to manage the state of the agent by defining and updating mechanisms such as beliefs, and interpersonal relationships.

The first step in creating the retrieval system in the Multi-Agent Framework (MAF) is to identify the types of retrieval nodes we want to incorporate. In most RAG
approaches, there is functionally one type of node -- the document or the passage. These are then incorporated into messages or in some cases system messages to be added into the attention window of the model. This brings the outside content into the context so that the model has a reference point beyond the trained weights to generate its answer. In our case retrieved information, goes into the agents \textit(state). The type of node helps determine which state (public, private, or semi private) to load the variables into. For our purposes we identify four main kinds of nodes, which can be retrieved to update state. As you will see in the next section, the models must be fine-tuned to better enable them to interpret the effects of state variables. All nodes are stored in an elastic cache index on AWS' Opensearch platform. Lookup occurs via KNN search in a shared topic oriented latent space. We architecturally prefer having more smaller indices than fewer larger indices. This enables for more refined fine-graned control of the access constraints, and topicality of the information being stored.

\subsection{Types of Retrieval Nodes}
\subsubsection{Knowledge Node}

Knowledge nodes are always loaded into \texit{public states}. Every knowledge node has a primary coordinate embedding, an adjacency matrix, and basic content information stored as a data object. Knowledge nodes are broken down into subtypes as follows:

\begin{itemize}
    \item[Documents] - A document is a collection of sections and basic citation information. The collection of sections is organized as a hash table representation of an adjacency matrix. Its embedding is the average of its consituent section embeddings. When loaded into the DocumentNode class it has a variety of useful utilities, for searching within a document, or finding nearby passages.
    \item[Sections] - A section is a collection of passages. It is adjacent to documents as a child. Its children are passages. It is also embedded as an average of passages and has its own utilities.
    \item[Passages] - A passage is a chunk of text, an embedding, and an adjacency matrix. We have found llmSherpa (citation needed) to be a useful resource in generating meaningful chunks. The passage can function as a generator with pointers to previous passages and next passages. Furthermore, there can be subtypes of passages, with further utilites. For example, in the debate language game having passages with underlined portions is useful, so there is a subtype called cards - which are essentially passages that have added highlighting utilities.
\end{itemize}

\subsubsection{Belief Node} - A belief node is a variation on a knowledge node which carries the additional important property of \textit{credence}. Credence is a measure of how strong the agent believes the information to be true. The scale is always from 0 to 1, where 0 is a contradiction, and 1 is a tautology. In other words, basic principles of Bayesian Epistemology hold for the credence of a belief. Beliefs also have adjacency matrices coordinating them with other beliefs and knowledge nodes, which are treated as evidence either in support of or in negation of a particular belief. Beliefs are always loaded into the \textit{private state} of an agent. There are two subtypes of beliefs

\begin{itemize}
    \item[Value] - A value a statement of preference that can be used for decision making. Values can be moral in nature, but can also be practical. For example, an agent might have a value that says "I prefer to be honest" or "I prefer to be efficient". These values can be used to guide the agent in decision making. The higer the credence of a value, the more likely the agent is to act in accordance with it.
    \item[Hypothesis] - A hypothesis is an uncertain statement of fact, which has evidence to support or negate it stored via an adjacency matrix. Its credence value is mathematically calculated according to prior beliefs (contingent beliefs) and the evidence available. When beliefs get modified they have the potential to change the credence of a downstream hypothesis. Hypotheses are used to guide the agent in its reasoning and decision making.
\end{itemize}

\subsubsection{Memory Node} A memory node is a useful structure for keeping track of relevant action history in a more explicity manner. Rather than tracking all messages, memory nodes are used to store and track messages according to relevance. An agent can recall past actions and outcomes using memory nodes. Memory nodes are also correlated with beliefs. They can be used as causal evidence. E.g. If action X led to state Y, then inductively we know that X can be a cause of Y. The more frequent the association is found, the stronger the causal link. Memory nodes can be stored at the individual level in private, but also at the tribal level in semi-private.

\subsubsection{Relationship Node} - The last type of node keeps track of agent and human relationships. There are two subtypes of relationships nodes. The relation node and the object node. Relationship Nodes are used to deal with the problem of other minds and to anticipate particular outcomes. They are trackedd inductively via experience, and are always kept private. This means that different agents have different perspectives on how relationships are going. In the context of agent-agent interactions, relationship nodes can be useful for identifying specialization. If a particular agent utilizing a particular model or MoE shows more promise than others at performing a task, then agents who identify this may be more likely to call upon that agent to perform the task in later episodes.

\begin{itemize}
    \item[Relation Node] - A relation node is a relationship between two agents. It has an adjacency matrix that keeps track of the history of interactions between the two agents. It also has a credence value that indicates how strong the relationship is. The credence value is calculated based on the frequency and quality of interactions between the two agents. The higher the credence value, the stronger the relationship. In example of a relation, may be "Trust", "Teaches". Relations are added lazily as agents interact with each other.
    \item[Object Node] - An object node represents the agents themselves. It has an adjacency matrix to other objects using relations as a coordinate.
\end{itemize}

\subsection{Dynamically Adding Nodes to the Retrieval System}

Generally speaking, nodes are added dynamically and lazily. This means that nodes are only added to the retrieval system when they are needed. For example, if an agent is seeking to find evidence or literature about open souce AI technology, it calls a method that first attempts to search the relevant index for nodes that currently exist. If the most proximate node as measured via an query embedding cosine similarity function, is above a threshold T, then the nodes get returned as output and loaded into the agents state. If no nodes exist above threshold T, then a series of API calls get made to various information sources like Google, Arxiv and others to find relevant articles on the subject. These articles are parsed and added to the retrieval network.

Belief nodes are also created lazily by the agent. Typically via debate or inter-agent disagreements. As agents advocate for particular positions, they update or create corresponding belief nodes. When they attempt to justify their reasoning using evidence, the evidence gets associated by adjacency matrices to the belief node. This is done in a way that is similar to how a human might justify a belief. If a belief is contradicted by evidence, then the credence of the belief is lowered. If the belief is supported by evidence, then the credence of the belief is raised. This is done in a way that is similar to how a human might justify a belief. Similarly, as events happen memory nodes get added and as new dialogs with other agents or users occur then relationship nodes get added.


\subsection{Retrieval Nodes and Adjacency Matrices: Nodes that Fire Together Wire Together}

The motivation behind adjacency matrices, beyond their obvious computational benefit, is to create a system that develops richer interconnections over time
via experience. Proximity is typically measured via cosine similarity against a query. But it may often be the case that the user wants contradictory information, or other peices of associated information that are connected via edges stored in an adjacency matrix. This edge representation is scalar (not just boolean) in value enabling sophisticated learned relationships over time. Furthermore, each node has a parameter theta, which corresponds to a weight matrix, that can be multipled by the adjacency matrix depending on the operation being performed. Initially, theta is just set to the identity matrix, but as data is accumulated the GNN can be fine-tuned to do a better job of retrieving associated nodes.
