## Abstract
- Todo

## Introduction
```latex
\section{Introduction}
AI Pluralism represents a pivotal shift in the development of artificial intelligence, offering a pathway towards more individualized and adaptable AI agents. We define AI Pluralism as:

\begin{quote}
\textit{Multi-Agent frameworks in which A.I. agents interact with other human or AI agents, each of whom are diverse in perspectives and positions producing complex ecosystem of thought and recursive strategic refinement, as is manifested in evolution and culture for humanity.}
\end{quote}

Many researchers have begun to explore how multi-agent systems might be configured using advanced LLMs. This transition from "mono-AI" to pluralistic AI represents an important paradigmatic shift in how one ought to approach doing AI research. Furthermore, it opens up the opportunities for other humanities based disciplines such as rhetoric, philosophy, game theory, anthropology, sociology, and psychology to contribute to the development of AI systems. The goal of this paper is to persuade the reader that not only is AI Pluralism valuable, but that it is also viable with the technology available today, and that with the right configuration it is possible to study such systems from many different perspectives.

AI Pluralism is a significant area of research because it offers great potential in alleviating many thorny issues in A.I. as outlined below.A

\begin{itemize}
    \item \textbf{Safety} AI Pluralism can help to make AI systems safer by providing a diverse set of perspectives and positions and systems of self-accountability in which the ecosystem creates incentives for agents to keep other agents in line with ethical norms, much as trading partnerships enhance and stabilize peace between nations.
    \item \textbf{Bias and Fairness:} AI Pluralism can help to mitigate bias in AI systems by providing a diverse set of perspectives and positions. This can help to ensure that AI systems are fair and equitable.
    \item \textbf{Explainability:} AI Pluralism can help to make AI systems more explainable by tracking dialogical patterns in thinking as opposed to being restricted to opaque assessments of the systems internal state. The act of AI community building by its nature brings the internal outwards into a dialogical framework of external problem solving and contemplation.
    \item \textbf{Robustness:} AI Pluralism can help to make AI systems more robust by providing a diverse array of roles and abilities that enable coverage of weak spots through oversight. Much as the police make it their goal to identify and prosecute intruders, its possible to envision a system in which certain AI agents monitor the health and status of various systems.
    \item \textbf{Adaptability:} AI Pluralism can help to make AI systems more adaptable by providing a diverse set of perspectives and positions. This can help to ensure that AI systems are able to respond to changing circumstances and environments.

\end{itemize}

This paper argues has three main contentions. First, that the study of AI Pluralism is necessary for the pursuit of AGI and ASI. Second, AI Pluralism enables beneficial properties that are not possible with mono-AI systems. Third, AI Pluralism is a viable with technologies available today with the right setup, generative language mechanics, and retrieval systems.

The remainder of the paper consists of a deeper exploration of three components of AI Pluralism - the retrieval systems, the language generation architecture, and the situational context that are necessary for AI Pluralism to be viable. It then explores some specific experimental implementations of the proposed research and the current results of that research. Then, we discusses a broader framework for conceptualizing the relationship between AI pluralism and consciousness. Finally, we outline milestones for future research and conclude with remarks on how to accelerate development in this area.
```

## Section: Related Work
```latex
\section{Related Work}
\subsection{Agent Architectures and Their Scaling Properties}
% masterman2024landscape, li2024agents

\subsection{Enhancements Through Collaboration}
% du2023improving, wang2024unleashing, Wu_2021


\subsection{Graph-Based Learning in Agent Systems}
% hu2024large, Wu_2021, fan2024graph


\subsection{Evaluation and Optimization of Multi-Agent Systems}
% Wu_2021, du2023improving, akiba2024evolutionary, li2024agents, chaudhari2024rlhf


\subsection{Contributions to AI Pluralism}
% ChristophCommunityInloop2021, Sorensen_2024

```

## section: Building Multi Agent Frameworks
* compare the idea of agentic frameworks to javascript frameworks like react, vue
* Introduce the idea of Agent State and its motivation
    * Agent State allows for more expicity control over attention
    * model agnostic agent persistence -- meaning an agent can theoretically use multiple models
    * The role of retrieval in individuating agents
* Retrieval In Terms of ElasticSearch Contexts:
    * Public
    * Semi-Private
    * Private
* Types of Retrieval Nodes:
    * Belief Nodes
    * Memory Nodes
    * Knowledge Nodes
        * Documents
        * Sections
        * Passages
    * Relationship Nodes
* Retrieval Nodes and Adjacency Matrices:
    * Leaning on Graph Machine Learning to enhance Retrieval on knowledge graphs
    * Tracking relationships through adjacency matrices and association learning
* Agent Components
    * Thinking about subtasks as components with pointers to to other components
    * Components load agents and run LLM or functional components
    * Designed to work with tools, plug and play
* Language Games
    * Why Games Matter -- Understanding the Reward
    * Game Theory and Agent States
    * Evolutionary Inheritance
* Model Merging and Evolutionary Algorithms
    * What is model merging, Why is it worthwhile
    * How do we use evolutionary algorithms to merge models
    * The role of Language Games


## section: The Retrieval Architecture
```latex
\section{The Retrieval Architecture}
When humans think, there are at least two core processes involved. The first is the retrieval of information in memory, whether it be memories of events, concepts, or facts. What is retrieved must then be coordinated with the current context and objectives within that context, to produce thought as typically represented both internally (and often externally) in the form of language. This section outlines an expanded principle of retrieval in which features of identity or long-term states are retrieved and continuously incorporated into language generation. Current retrieval mechanisms such as RAG are useful for citing or justifying responses and mitigating hallucinations. However, databases can be used to do more than retrieve information, they can also be used to manage the state of the agent by defining and updating mechanisms such as beliefs, and interpersonal relationships.

\subsection{LLMs & Epistemic Primitives}
Consciousness is not binary. It is not the case that one suddenly becomes conscious once the right set of attributes are in place. Instead, we should think of consciousness as scalar, which grows in proportion to the mechanisms that create useful complexity in the thinking agent. Some may argue for a more refined perspective, suggesting that consciousness is not binary, but it is quantic in nature. In other words, that there are mechanisms that when introduce result in large steps disproportionately such that qualities "emerge" as a result of interactions that have become newly available. Whether conceived of as quantic or scalar, we stand firmly against the idea that consciousness is a property that "appears" when the right conditions are met.

This suggests that there are components to consciousness, and that as components are introduced consciousness grows. As components are removed or reduced consciousness becomes reduced. For example, remembering historical events is a component (made up of other components as well) that contributes significantly to factors like one's perceived identity. Remembering historical events requires certain components to already be in place, and at the same time enables other components to exist if it is in place. This would suggest that a person who has a much better memory than other person may have relatively less consciousness. However, since consciousness is not a uni-variate system, it may also be the case (and often is) that the person with reduced memory skills makes up for it in other ways. I will refer to these components of consciousness going forward as \textbf{epistemic primitives}.

\begin{quote}
Epistemic Primitives are the most basic components of consciousness that contribute to the complexity of thought that is possible for thinking agents. In other words, epistemic primitives are the building blocks of consciousness.
\end{quote}

Epistemic Primitives should not be conceptualized in an arboreal fashion. In other words, while epistmic primitives may enhance or enable other epistemic primitives, we should not think not think about their relationships as a hierarchical set of dependencies. The trap with conceptualizing epistmic primitives in an arboreal fashion is the strong tendency to seek a fundamental root node, which does not exist. Instead, epistemic primitives should be thought of as a network of components that are interdependent and that can be added or removed in a variety of ways. A better metaphor for how epistimic primitves likely interact to form consciousness is how Deleuze describes rhizomatic structures in \textit{A Thousand Plateaus}. There is no golden nugget, but instead a rich interplay of various components that make properties emerge as a result of scaling or level leaping (in a quantic framework)

```

## [the_generative_architecture.tex](sections%2Fthe_generative_architecture.tex)
* Discuss Model Merging and Evolutionary Algorithms
* Using MoE's more effectively 
* Loading Lora Adapters on the Fly
* Supervised Fine Tuning on Specific Agent Components

## [the_situational_context.tex](sections%2Fthe_situational_context.tex)

* Defining Language Games
* Examples of Language Games
* Evolution -- Why games works as a proxy

## [Results](sections%2Fresults.tex)

* Discuss the results of the experiments
* Table showing how Multi Agent Architectures compare to Mono Agent Architectures

## [Discussion](sections%2Fdiscussion.tex)

```latex
\section{Discussion}
The discussion section reflects on the results, considering the role of language in consciousness as debated by Dennett and Chomsky, and evaluates the impact of culture and future research directions in AI Pluralism.

```

## [Future Work & Milestones](sections%2Ffuture_work.tex)

```latex
\section{Milestones}
This part of the paper proposes a set of milestones for measuring progress in AI Pluralism, including the complexity of situations, progress in language games, and sophistication of retrieval mechanisms.

```
## Conclusion
```latex
\section{Conclusion}
The conclusion summarizes the paper's contributions to AI Pluralism, highlighting the potential for more diverse, adaptable, and innovative AI systems and suggesting avenues for future research.

```


## References
```bibtex
@article{masterman2024landscape,
      title={The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey},
      author={Tula Masterman and Sandi Besen and Mason Sawtell and Alex Chao},
      year={2024},
      eprint={2404.11584},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url = {https://arxiv.org/abs/2404.11584},
  abstract = {This survey paper examines the recent advancements in AI agent implementations, with a focus on
their ability to achieve complex goals that require enhanced reasoning, planning, and tool execution
capabilities. The primary objectives of this work are to a) communicate the current capabilities and
limitations of existing AI agent implementations, b) share insights gained from our observations
of these systems in action, and c) suggest important considerations for future developments in AI
agent design. We achieve this by providing overviews of single-agent and multi-agent architectures,
identifying key patterns and divergences in design choices, and evaluating their overall impact on
accomplishing a provided goal. Our contribution outlines key themes when selecting an agentic
architecture, the impact of leadership on agent systems, agent communication styles, and key phases
for planning, execution, and reflection that enable robust AI agent systems.},
}


@misc{fan2024graph,
      title={Graph Machine Learning in the Era of Large Language Models (LLMs)},
      author={Wenqi Fan and Shijie Wang and Jiani Huang and Zhikai Chen and Yu Song and Wenzhuo Tang and Haitao Mao and Hui Liu and Xiaorui Liu and Dawei Yin and Qing Li},
      year={2024},
      eprint={2404.14928},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
  url = {https://arxiv.org/abs/2404.14928},
  abstract = {Graphs play an important role in representing complex relationships in various domains like social networks, knowledge
graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in
Graph Machine Learning (Graph ML), facilitating the representation and processing of graph structures. Recently, LLMs have
demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision
and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts
have been made to explore the potential of LLMs in advancing Graph ML’s generalization, transferability, and few-shot learning ability.
Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning
capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress
of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to
provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in
Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and
address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can
enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications
and discuss the potential future directions in this promising field.},
}

@misc{chaudhari2024rlhf,
      title={RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs},
      author={Shreyas Chaudhari and Pranjal Aggarwal and Vishvak Murahari and Tanmay Rajpurohit and Ashwin Kalyan and Karthik Narasimhan and Ameet Deshpande and Bruno Castro da Silva},
      year={2024},
      eprint={2404.08555},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
    url = {https://arxiv.org/abs/2404.08555},
    abstract = {However, training LLMs to serve as effective assistants for humans requires careful consideration.
A promising approach is reinforcement learning from human feedback (RLHF), which leverages
human feedback to update the model in accordance with human preferences and mitigate issues like
toxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely entangled with initial
design choices that popularized the method and current research focuses on augmenting those choices
rather than fundamentally improving the framework. In this paper, we analyze RLHF through the
lens of reinforcement learning principles to develop an understanding of its fundamentals, dedicating
substantial focus to the core component of RLHF—the reward model. Our study investigates
modeling choices, caveats of function approximation, and their implications on RLHF training
algorithms, highlighting the underlying assumptions made about the expressivity of reward. Our
analysis improves the understanding of the role of reward models and methods for their training,
concurrently revealing limitations of the current methodology. We characterize these limitations,
including incorrect generalization, model misspecification, and the sparsity of feedback, along with
their impact on the performance of a language model. The discussion and analysis are substantiated
by a categorical review of current literature, serving as a reference for researchers and practitioners to
understand the challenges of RLHF and build upon existing efforts.},
}


@misc{wang2024unleashing,
      title={Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration},
      author={Zhenhailong Wang and Shaoguang Mao and Wenshan Wu and Tao Ge and Furu Wei and Heng Ji},
      year={2024},
      eprint={2307.05300},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
    url = {https://arxiv.org/abs/2307.05300},
    abstract = {Human intelligence thrives on cognitive synergy,
where collaboration among different
minds yield superior outcomes compared to isolated
individuals. In this work, we propose Solo
Performance Prompting (SPP), which transforms
a single LLM into a cognitive synergist
by engaging in multi-turn self-collaboration
with multiple personas. A cognitive synergist
is an intelligent agent that collaboratively
combines multiple minds’ strengths and knowledge
to enhance problem-solving in complex
tasks. By dynamically identifying and simulating
different personas based on task inputs,
SPP unleashes the potential of cognitive synergy
in LLMs. Our in-depth analysis shows
that assigning multiple fine-grained personas
in LLMs improves problem-solving abilities
compared to using a single or fixed number
of personas. We evaluate SPP on three challenging
tasks: Trivia Creative Writing, Codenames
Collaborative, and Logic Grid Puzzle,
encompassing both knowledge-intensive and
reasoning-intensive types. Unlike previous
works, such as Chain-of-Thought, that solely
enhance the reasoning abilities in LLMs, experimental
results demonstrate that SPP effectively
reduces factual hallucination, and maintains
strong reasoning capabilities. Additionally,
comparative experiments show that cognitive
synergy only emerges in GPT-4 and
does not appear in less capable models, such
as GPT-3.5-turbo and Llama2-13b-chat, which
draws an interesting analogy to human development.
Code, data, and prompts can be found
at: https://github.com/MikeWangWZHL/
Solo-Performance-Prompting.git},
    github={https://github.com/MikeWangWZHL/
Solo-Performance-Prompting.git}
}

@misc{hu2024large,
      title={Large Language Model Meets Graph Neural Network in Knowledge Distillation},
      author={Shengxiang Hu and Guobing Zou and Song Yang and Yanglan Gan and Bofeng Zhang and Yixin Chen},
      year={2024},
      eprint={2402.05894},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
    url={https://arxiv.org/abs/2402.05894},
    abstract = {Despite recent community revelations about the advancements and
potential applications of Large Language Models (LLMs) in understanding
Text-Attributed Graph (TAG), the deployment of LLMs for
production is hindered by its high computational and storage requirements,
as well as long latencies during model inference. Simultaneously,
although traditional Graph Neural Networks (GNNs) are light
weight and adept at learning structural features of graphs, their ability
to grasp the complex semantics in TAG is somewhat constrained
for real applications. To address these limitations, we concentrate
on the downstream task of node classification in TAG and propose a
novel graph knowledge distillation framework, termed Linguistic
Graph Knowledge Distillation (LinguGKD), using LLMs as teacher
models and GNNs as student models for knowledge distillation. It involves
TAG-oriented instruction tuning of LLM on designed tailored
prompts, followed by propagating knowledge and aligning the hierarchically
learned node features from the teacher LLM to the student
GNN in latent space, employing a layer-adaptive contrastive learning
strategy. Through extensive experiments on a variety of LLM and
GNN models and multiple benchmark datasets, the proposed LinguGKD
significantly boosts the student GNN’s predictive accuracy
and convergence rate, without the need of extra data or model parameters.
Compared to teacher LLM, distilled GNN achieves superior
inference speed equipped with much fewer computing and storage
demands, when surpassing the teacher LLM’s classification accuracy
on some of benchmark datasets.},
}

@misc{li2024agents,
      title={More Agents Is All You Need},
      author={Junyou Li and Qin Zhang and Yangbin Yu and Qiang Fu and Deheng Ye},
      year={2024},
      eprint={2402.05120},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
    url = {https://arxiv.org/abs/2402.05120},
    abstract = {We find that, simply via a sampling-and-voting
method, the performance of large language models
(LLMs) scales with the number of agents instantiated.
Also, this method is orthogonal to
existing complicated methods to further enhance
LLMs, while the degree of enhancement is correlated
to the task difficulty. We conduct comprehensive
experiments on a wide range of LLM
benchmarks to verify the presence of our finding,
and to study the properties that can facilitate its
occurrence. Our code is publicly available at: Git.},
}

@misc{akiba2024evolutionary,
      title={Evolutionary Optimization of Model Merging Recipes},
      author={Takuya Akiba and Makoto Shing and Yujin Tang and Qi Sun and David Ha},
      year={2024},
      eprint={2403.13187},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
    url = {https://arxiv.org/abs/2403.13187},
    abstract = {We present a novel application of evolutionary algorithms to automate the creation
of powerful foundation models. While model merging has emerged as a promising
approach for LLM development due to its cost-effectiveness, it currently relies on
human intuition and domain knowledge, limiting its potential. Here, we propose an
evolutionary approach that overcomes this limitation by automatically discovering
effective combinations of diverse open-source models, harnessing their collective
intelligence without requiring extensive additional training data or compute. Our
approach operates in both parameter space and data flow space, allowing for
optimization beyond just the weights of the individual models. This approach even
facilitates cross-domain merging, generating models like a Japanese LLM with
Math reasoning capabilities. Surprisingly, our Japanese Math LLM achieved stateof-
the-art performance on a variety of established Japanese LLM benchmarks, even
surpassing models with significantly more parameters, despite not being explicitly
trained for such tasks. Furthermore, a culturally-aware Japanese VLM generated
through our approach demonstrates its effectiveness in describing Japanese culturespecific
content, outperforming previous Japanese VLMs. This work not only
contributes new state-of-the-art models back to the open-source community, but
also introduces a new paradigm for automated model composition, paving the way
for exploring alternative, efficient approaches to foundation model development.},
}

@misc{du2023improving,
      title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
      author={Yilun Du and Shuang Li and Antonio Torralba and Joshua B. Tenenbaum and Igor Mordatch},
      year={2023},
      eprint={2305.14325},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
    url = {https://arxiv.org/abs/2305.14325},
    abstract = {Large language models (LLMs) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such "society of minds" approach has the potential to significantly advance the capabilities of LLMs and pave the way for further breakthroughs in language generation and understanding.},
}

@article{Wu_2021,
   title={A Comprehensive Survey on Graph Neural Networks},
   volume={32},
   ISSN={2162-2388},
   url={http://dx.doi.org/10.1109/TNNLS.2020.2978386},
   DOI={10.1109/tnnls.2020.2978386},
   number={1},
   journal={IEEE Transactions on Neural Networks and Learning Systems},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
   year={2021},
   month=jan, pages={4–24},
abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.},}


@article{Sorensen_2024,
   title={Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties},
   volume={38},
   ISSN={2159-5399},
   url={http://dx.doi.org/10.1609/aaai.v38i18.29970},
   DOI={10.1609/aaai.v38i18.29970},
   number={18},
   journal={Proceedings of the AAAI Conference on Artificial Intelligence},
   publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
   author={Sorensen, Taylor and Jiang, Liwei and Hwang, Jena D. and Levine, Sydney and Pyatkin, Valentina and West, Peter and Dziri, Nouha and Lu, Ximing and Rao, Kavel and Bhagavatula, Chandra and Sap, Maarten and Tasioulas, John and Choi, Yejin},
   year={2024},
   month=mar, pages={19937–19947},
abstract = {Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction.
We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented.
With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.},}


@article{ChristophCommunityInloop2021,
author = {Häußermann, Johann and Lütge, Christoph},
year = {2021},
month = {03},
pages = {},
title = {Community-in-the-loop: towards pluralistic value creation in AI, or—why AI needs business ethics},
volume = {2},
journal = {AI and Ethics},
doi = {10.1007/s43681-021-00047-2},
    abstract={Today, due to growing computing power and the increasing availability of high-quality datasets, artificial intelligence (AI) technologies are entering many areas of our everyday life. Thereby, however, significant ethical concerns arise, including issues of fairness, privacy and human autonomy. By aggregating current concerns and criticisms, we identify five crucial shortcomings of the current debate on the ethics of AI. On the threshold of a third wave of AI ethics, we find that the field eventually fails to take sufficient account of the business context and deep societal value conflicts the use of AI systems may evoke. For even a perfectly fair AI system, regardless of its feasibility, may be ethically problematic, a too narrow focus on the ethical implications of technical systems alone seems insufficient. Therefore, we introduce a business ethics perspective based on the normative theory of contractualism and conceptualise ethical implications as conflicts between values of diverse stakeholders. We argue that such value conflicts can be resolved by an account of deliberative order ethics holding that stakeholders of an economic community deliberate the costs and benefits and agree on rules for acceptable trade-offs when AI systems are employed. This allows AI ethics to consider business practices, to recognise the role of firms, and ethical AI not being at risk to provide a competitive disadvantage or in conflict with the current functioning of economic markets. By introducing deliberative order ethics, we thus seek to do justice to the fundamental normative and political dimensions at the core of AI ethics.}
}
```