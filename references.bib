@article{masterman2024landscape,
      title={The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey},
      author={Tula Masterman and Sandi Besen and Mason Sawtell and Alex Chao},
      year={2024},
      journal = {arxiv},
      eprint={2404.11584},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
  url = {https://arxiv.org/abs/2404.11584},
  abstract = {This survey paper examines the recent advancements in AI agent implementations, with a focus on
their ability to achieve complex goals that require enhanced reasoning, planning, and tool execution
capabilities. The primary objectives of this work are to a) communicate the current capabilities and
limitations of existing AI agent implementations, b) share insights gained from our observations
of these systems in action, and c) suggest important considerations for future developments in AI
agent design. We achieve this by providing overviews of single-agent and multi-agent architectures,
identifying key patterns and divergences in design choices, and evaluating their overall impact on
accomplishing a provided goal. Our contribution outlines key themes when selecting an agentic
architecture, the impact of leadership on agent systems, agent communication styles, and key phases
for planning, execution, and reflection that enable robust AI agent systems.},
}


@misc{fan2024graph,
      title={Graph Machine Learning in the Era of Large Language Models (LLMs)}, 
      author={Wenqi Fan and Shijie Wang and Jiani Huang and Zhikai Chen and Yu Song and Wenzhuo Tang and Haitao Mao and Hui Liu and Xiaorui Liu and Dawei Yin and Qing Li},
      year={2024},
      eprint={2404.14928},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
  url = {https://arxiv.org/abs/2404.14928},
  abstract = {Graphs play an important role in representing complex relationships in various domains like social networks, knowledge
graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in
Graph Machine Learning (Graph ML), facilitating the representation and processing of graph structures. Recently, LLMs have
demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision
and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts
have been made to explore the potential of LLMs in advancing Graph ML’s generalization, transferability, and few-shot learning ability.
Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning
capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress
of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to
provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in
Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and
address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can
enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications
and discuss the potential future directions in this promising field.},
}

@misc{chaudhari2024rlhf,
      title={RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs},
      author={Shreyas Chaudhari and Pranjal Aggarwal and Vishvak Murahari and Tanmay Rajpurohit and Ashwin Kalyan and Karthik Narasimhan and Ameet Deshpande and Bruno Castro da Silva},
      year={2024},
      eprint={2404.08555},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
    url = {https://arxiv.org/abs/2404.08555},
    abstract = {However, training LLMs to serve as effective assistants for humans requires careful consideration.
A promising approach is reinforcement learning from human feedback (RLHF), which leverages
human feedback to update the model in accordance with human preferences and mitigate issues like
toxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely entangled with initial
design choices that popularized the method and current research focuses on augmenting those choices
rather than fundamentally improving the framework. In this paper, we analyze RLHF through the
lens of reinforcement learning principles to develop an understanding of its fundamentals, dedicating
substantial focus to the core component of RLHF—the reward model. Our study investigates
modeling choices, caveats of function approximation, and their implications on RLHF training
algorithms, highlighting the underlying assumptions made about the expressivity of reward. Our
analysis improves the understanding of the role of reward models and methods for their training,
concurrently revealing limitations of the current methodology. We characterize these limitations,
including incorrect generalization, model misspecification, and the sparsity of feedback, along with
their impact on the performance of a language model. The discussion and analysis are substantiated
by a categorical review of current literature, serving as a reference for researchers and practitioners to
understand the challenges of RLHF and build upon existing efforts.},
}


@misc{wang2024unleashing,
      title={Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration}, 
      author={Zhenhailong Wang and Shaoguang Mao and Wenshan Wu and Tao Ge and Furu Wei and Heng Ji},
      year={2024},
      eprint={2307.05300},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
    url = {https://arxiv.org/abs/2307.05300},
    abstract = {Human intelligence thrives on cognitive synergy,
where collaboration among different
minds yield superior outcomes compared to isolated
individuals. In this work, we propose Solo
Performance Prompting (SPP), which transforms
a single LLM into a cognitive synergist
by engaging in multi-turn self-collaboration
with multiple personas. A cognitive synergist
is an intelligent agent that collaboratively
combines multiple minds’ strengths and knowledge
to enhance problem-solving in complex
tasks. By dynamically identifying and simulating
different personas based on task inputs,
SPP unleashes the potential of cognitive synergy
in LLMs. Our in-depth analysis shows
that assigning multiple fine-grained personas
in LLMs improves problem-solving abilities
compared to using a single or fixed number
of personas. We evaluate SPP on three challenging
tasks: Trivia Creative Writing, Codenames
Collaborative, and Logic Grid Puzzle,
encompassing both knowledge-intensive and
reasoning-intensive types. Unlike previous
works, such as Chain-of-Thought, that solely
enhance the reasoning abilities in LLMs, experimental
results demonstrate that SPP effectively
reduces factual hallucination, and maintains
strong reasoning capabilities. Additionally,
comparative experiments show that cognitive
synergy only emerges in GPT-4 and
does not appear in less capable models, such
as GPT-3.5-turbo and Llama2-13b-chat, which
draws an interesting analogy to human development.
Code, data, and prompts can be found
at: https://github.com/MikeWangWZHL/
Solo-Performance-Prompting.git},
    github={https://github.com/MikeWangWZHL/
Solo-Performance-Prompting.git}
}

@misc{hu2024large,
      title={Large Language Model Meets Graph Neural Network in Knowledge Distillation}, 
      author={Shengxiang Hu and Guobing Zou and Song Yang and Yanglan Gan and Bofeng Zhang and Yixin Chen},
      year={2024},
      eprint={2402.05894},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
    url={https://arxiv.org/abs/2402.05894},
    abstract = {Despite recent community revelations about the advancements and
potential applications of Large Language Models (LLMs) in understanding
Text-Attributed Graph (TAG), the deployment of LLMs for
production is hindered by its high computational and storage requirements,
as well as long latencies during model inference. Simultaneously,
although traditional Graph Neural Networks (GNNs) are light
weight and adept at learning structural features of graphs, their ability
to grasp the complex semantics in TAG is somewhat constrained
for real applications. To address these limitations, we concentrate
on the downstream task of node classification in TAG and propose a
novel graph knowledge distillation framework, termed Linguistic
Graph Knowledge Distillation (LinguGKD), using LLMs as teacher
models and GNNs as student models for knowledge distillation. It involves
TAG-oriented instruction tuning of LLM on designed tailored
prompts, followed by propagating knowledge and aligning the hierarchically
learned node features from the teacher LLM to the student
GNN in latent space, employing a layer-adaptive contrastive learning
strategy. Through extensive experiments on a variety of LLM and
GNN models and multiple benchmark datasets, the proposed LinguGKD
significantly boosts the student GNN’s predictive accuracy
and convergence rate, without the need of extra data or model parameters.
Compared to teacher LLM, distilled GNN achieves superior
inference speed equipped with much fewer computing and storage
demands, when surpassing the teacher LLM’s classification accuracy
on some of benchmark datasets.},
}

@misc{li2024agents,
      title={More Agents Is All You Need}, 
      author={Junyou Li and Qin Zhang and Yangbin Yu and Qiang Fu and Deheng Ye},
      year={2024},
      eprint={2402.05120},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
    url = {https://arxiv.org/abs/2402.05120},
    abstract = {We find that, simply via a sampling-and-voting
method, the performance of large language models
(LLMs) scales with the number of agents instantiated.
Also, this method is orthogonal to
existing complicated methods to further enhance
LLMs, while the degree of enhancement is correlated
to the task difficulty. We conduct comprehensive
experiments on a wide range of LLM
benchmarks to verify the presence of our finding,
and to study the properties that can facilitate its
occurrence. Our code is publicly available at: Git.},
}

@misc{akiba2024evolutionary,
      title={Evolutionary Optimization of Model Merging Recipes}, 
      author={Takuya Akiba and Makoto Shing and Yujin Tang and Qi Sun and David Ha},
      year={2024},
      eprint={2403.13187},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
    url = {https://arxiv.org/abs/2403.13187},
    abstract = {We present a novel application of evolutionary algorithms to automate the creation
of powerful foundation models. While model merging has emerged as a promising
approach for LLM development due to its cost-effectiveness, it currently relies on
human intuition and domain knowledge, limiting its potential. Here, we propose an
evolutionary approach that overcomes this limitation by automatically discovering
effective combinations of diverse open-source models, harnessing their collective
intelligence without requiring extensive additional training data or compute. Our
approach operates in both parameter space and data flow space, allowing for
optimization beyond just the weights of the individual models. This approach even
facilitates cross-domain merging, generating models like a Japanese LLM with
Math reasoning capabilities. Surprisingly, our Japanese Math LLM achieved stateof-
the-art performance on a variety of established Japanese LLM benchmarks, even
surpassing models with significantly more parameters, despite not being explicitly
trained for such tasks. Furthermore, a culturally-aware Japanese VLM generated
through our approach demonstrates its effectiveness in describing Japanese culturespecific
content, outperforming previous Japanese VLMs. This work not only
contributes new state-of-the-art models back to the open-source community, but
also introduces a new paradigm for automated model composition, paving the way
for exploring alternative, efficient approaches to foundation model development.},
}

@misc{du2023improving,
      title={Improving Factuality and Reasoning in Language Models through Multiagent Debate}, 
      author={Yilun Du and Shuang Li and Antonio Torralba and Joshua B. Tenenbaum and Igor Mordatch},
      year={2023},
      eprint={2305.14325},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
    url = {https://arxiv.org/abs/2305.14325},
    abstract = {Large language models (LLMs) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such "society of minds" approach has the potential to significantly advance the capabilities of LLMs and pave the way for further breakthroughs in language generation and understanding.},
}

@article{Wu_2021,
   title={A Comprehensive Survey on Graph Neural Networks},
   volume={32},
   ISSN={2162-2388},
   url={http://dx.doi.org/10.1109/TNNLS.2020.2978386},
   DOI={10.1109/tnnls.2020.2978386},
   number={1},
   journal={IEEE Transactions on Neural Networks and Learning Systems},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
   year={2021},
   month=jan, pages={4–24},
abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes, benchmark data sets, and model evaluation of graph neural networks. Finally, we propose potential research directions in this rapidly growing field.},}


@article{Sorensen_2024,
   title={Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties},
   volume={38},
   ISSN={2159-5399},
   url={http://dx.doi.org/10.1609/aaai.v38i18.29970},
   DOI={10.1609/aaai.v38i18.29970},
   number={18},
   journal={Proceedings of the AAAI Conference on Artificial Intelligence},
   publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
   author={Sorensen, Taylor and Jiang, Liwei and Hwang, Jena D. and Levine, Sydney and Pyatkin, Valentina and West, Peter and Dziri, Nouha and Lu, Ximing and Rao, Kavel and Bhagavatula, Chandra and Sap, Maarten and Tasioulas, John and Choi, Yejin},
   year={2024},
   month=mar, pages={19937–19947},
abstract = {Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction.
We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented.
With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.},}


@article{ChristophCommunityInloop2021,
author = {Häußermann, Johann and Lütge, Christoph},
year = {2021},
month = {03},
pages = {},
title = {Community-in-the-loop: towards pluralistic value creation in AI, or—why AI needs business ethics},
volume = {2},
journal = {AI and Ethics},
doi = {10.1007/s43681-021-00047-2},
    abstract={Today, due to growing computing power and the increasing availability of high-quality datasets, artificial intelligence (AI) technologies are entering many areas of our everyday life. Thereby, however, significant ethical concerns arise, including issues of fairness, privacy and human autonomy. By aggregating current concerns and criticisms, we identify five crucial shortcomings of the current debate on the ethics of AI. On the threshold of a third wave of AI ethics, we find that the field eventually fails to take sufficient account of the business context and deep societal value conflicts the use of AI systems may evoke. For even a perfectly fair AI system, regardless of its feasibility, may be ethically problematic, a too narrow focus on the ethical implications of technical systems alone seems insufficient. Therefore, we introduce a business ethics perspective based on the normative theory of contractualism and conceptualise ethical implications as conflicts between values of diverse stakeholders. We argue that such value conflicts can be resolved by an account of deliberative order ethics holding that stakeholders of an economic community deliberate the costs and benefits and agree on rules for acceptable trade-offs when AI systems are employed. This allows AI ethics to consider business practices, to recognise the role of firms, and ethical AI not being at risk to provide a competitive disadvantage or in conflict with the current functioning of economic markets. By introducing deliberative order ethics, we thus seek to do justice to the fundamental normative and political dimensions at the core of AI ethics.}
}

@misc{sorensen2023value,
      title={Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties},
      author={Taylor Sorensen and Liwei Jiang and Jena Hwang and Sydney Levine and Valentina Pyatkin and Peter West and Nouha Dziri and Ximing Lu and Kavel Rao and Chandra Bhagavatula and Maarten Sap and John Tasioulas and Yejin Choi},
      year={2023},
      eprint={2309.00779},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}